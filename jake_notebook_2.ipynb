{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acct_type', 'approx_payout_date', 'body_length', 'channels', 'country',\n",
       "       'currency', 'delivery_method', 'description', 'email_domain',\n",
       "       'event_created', 'event_end', 'event_published', 'event_start',\n",
       "       'fb_published', 'gts', 'has_analytics', 'has_header', 'has_logo',\n",
       "       'listed', 'name', 'name_length', 'num_order', 'num_payouts',\n",
       "       'object_id', 'org_desc', 'org_facebook', 'org_name', 'org_twitter',\n",
       "       'payee_name', 'payout_type', 'previous_payouts', 'sale_duration',\n",
       "       'sale_duration2', 'show_map', 'ticket_types', 'user_age',\n",
       "       'user_created', 'user_type', 'venue_address', 'venue_country',\n",
       "       'venue_latitude', 'venue_longitude', 'venue_name', 'venue_state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data/data.json')\n",
    "df.head()\n",
    "df.describe()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fraudster_event', 'premium', 'spammer_warn', 'fraudster',\n",
       "       'spammer_limited', 'spammer_noinvite', 'locked', 'tos_lock',\n",
       "       'tos_warn', 'fraudster_att', 'spammer_web', 'spammer'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_type'].unique()\n",
    "df['acct_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "14332     True\n",
       "14333    False\n",
       "14334    False\n",
       "14335    False\n",
       "14336     True\n",
       "Name: fraud, Length: 14337, dtype: bool"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "df['fraud'] = df['acct_type'].apply(lambda x: 'fraud' in x)\n",
    "df['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['acct_type'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13044"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "df[df['fraud']==True]['fraud'].count()\n",
    "df[df['fraud']==False]['fraud'].count()\n",
    "# Fraud = ~10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "features = ['body_length'    ,\n",
    "'channels'       ,\n",
    "'delivery_method',\n",
    "'has_logo'       ,\n",
    "'name_length'    ,\n",
    "'org_facebook'   ,\n",
    "'org_twitter'    ,\n",
    "'sale_duration'  ,\n",
    "'sale_duration2' ,\n",
    "'user_age'       ,\n",
    "'fraud']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoping the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) Preprocessing\n",
    "- Convert dates to dt format\n",
    "- Convert binary categories to boolean\n",
    "\n",
    "2.) Models to Try\n",
    "\n",
    "3.) Metric to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "X = df.drop(columns=['fraud'])\n",
    "y = df['fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body_length        3533\n",
       "channels           3533\n",
       "delivery_method    3533\n",
       "has_logo           3533\n",
       "name_length        3533\n",
       "org_facebook       3533\n",
       "org_twitter        3533\n",
       "sale_duration      3533\n",
       "sale_duration2     3533\n",
       "user_age           3533\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.count()\n",
    "X_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def logistic_model(X, y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    #select the columns with numerical/categorical data\n",
    "    #X = X.loc[:, (X.dtypes == np.float64) or (X.dtypes == np.int64)]\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y)\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    #fit model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_valid, y_valid)\n",
    "    coeffs = pd.DataFrame(model.coef_, columns=X_train.columns)\n",
    "    print(coeffs)\n",
    "    tn, fp, fn, tp = confusion_matrix(model.predict(X_valid), y_valid).ravel()\n",
    "    \n",
    "    return model, accuracy, (tn, fp, fn, tp)\n",
    "\n",
    "\n",
    "def SGD_model(X, y):\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y)\n",
    "    \n",
    "    #fit model\n",
    "    model = SGDClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_valid, y_valid)\n",
    "    tn, fp, fn, tp = confusion_matrix(model.predict(X_valid), y_valid).ravel()\n",
    "  \n",
    "    \n",
    "    return model, accuracy, (tn, fp, fn, tp)\n",
    "    \n",
    "def rf_model(X,y):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y)\n",
    "    \n",
    "    #fit model\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_valid, y_valid)\n",
    "    tn, fp, fn, tp = confusion_matrix(model.predict(X_valid), y_valid).ravel()\n",
    "    \n",
    "    \n",
    "    return model, accuracy, (tn, fp, fn, tp)\n",
    "\n",
    "def gradient_model(X,y):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y)\n",
    "    \n",
    "    #fit model\n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_valid, y_valid)\n",
    "    tn, fp, fn, tp = confusion_matrix(model.predict(X_valid), y_valid).ravel()\n",
    "    \n",
    "    \n",
    "    return model, accuracy, (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   body_length  channels  delivery_method  has_logo  name_length  \\\n",
      "0     -0.00006 -0.028705        -0.081677 -0.019338    -0.004285   \n",
      "\n",
      "   org_facebook  org_twitter  sale_duration  sale_duration2  user_age  \n",
      "0     -0.072061    -0.162572       0.030174       -0.056563 -0.003011  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobmullins/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 0.92,\n",
       " (2438, 212, 0, 0))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "               early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "               l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "               max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "               power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "               validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " 0.9230188679245283,\n",
       " (2349, 115, 89, 97))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                            learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                            max_features=None, max_leaf_nodes=None,\n",
       "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                            min_samples_leaf=1, min_samples_split=2,\n",
       "                            min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                            n_iter_no_change=None, presort='deprecated',\n",
       "                            random_state=None, subsample=1.0, tol=0.0001,\n",
       "                            validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False),\n",
       " 0.969811320754717,\n",
       " (2409, 51, 29, 161))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False),\n",
       " 0.9633962264150944,\n",
       " (2411, 70, 27, 142))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "random_subset = df3.sample(n=100)\n",
    "random_subset.to_csv('test_script_examples.csv', index=False)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('test_script_examples.csv') as fd:\n",
    "#    reader=csv.reader(fd)\n",
    "#    #test_row=next(reader)\n",
    "#    next(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_script_examples.csv') as fd:\n",
    "    reader=csv.reader(fd)\n",
    "    interestingrow=[row for idx, row in enumerate(reader) if idx in [np.random.randint(1,100)]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['108', '11', '1.0', '1', '38', '7.0', '8.0', '207.0', '214', '1056', 'False']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interestingrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for x in interestingrow:\n",
    "    try:l.append(float(x))\n",
    "    except:l.append(bool(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['108', '11', '1.0', '1', '38', '7.0', '8.0', '207.0', '214', '1056', 'False']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interestingrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.080e+02, 1.100e+01, 1.000e+00, 1.000e+00, 3.800e+01, 7.000e+00,\n",
       "       8.000e+00, 2.070e+02, 2.140e+02, 1.056e+03])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(l[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for predict.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_script_examples.csv') as fd:\n",
    "    reader=csv.reader(fd)\n",
    "    interestingrow=[row for idx, row in enumerate(reader) if idx in (0,np.random.randint(1,100))][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['514', '8', '1.0', '1', '56', '23.0', '14.0', '86.0', '86', '378', 'False']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interestingrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for x in interestingrow:\n",
    "    try:l.append(float(x))\n",
    "    except:l.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[514.0, 8.0, 1.0, 1.0, 56.0, 23.0, 14.0, 86.0, 86.0, 378.0, 'False']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=pd.Series(l[:-1])\n",
    "truth=pd.Series(l[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([514.,   8.,   1.,   1.,  56.,  23.,  14.,  86.,  86., 378.])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, accuracy, (tn, fp, fn, tp) = rf_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelpickle.joblib']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pickle model\n",
    "from joblib import dump, load\n",
    "dump(model, 'modelpickle.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpickle\n",
    "model = load('modelpickle.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array(input).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['False'], dtype=object)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
