{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acct_type', 'approx_payout_date', 'body_length', 'channels', 'country',\n",
       "       'currency', 'delivery_method', 'description', 'email_domain',\n",
       "       'event_created', 'event_end', 'event_published', 'event_start',\n",
       "       'fb_published', 'gts', 'has_analytics', 'has_header', 'has_logo',\n",
       "       'listed', 'name', 'name_length', 'num_order', 'num_payouts',\n",
       "       'object_id', 'org_desc', 'org_facebook', 'org_name', 'org_twitter',\n",
       "       'payee_name', 'payout_type', 'previous_payouts', 'sale_duration',\n",
       "       'sale_duration2', 'show_map', 'ticket_types', 'user_age',\n",
       "       'user_created', 'user_type', 'venue_address', 'venue_country',\n",
       "       'venue_latitude', 'venue_longitude', 'venue_name', 'venue_state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data/data.json')\n",
    "df.head()\n",
    "df.describe()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fraudster_event', 'premium', 'spammer_warn', 'fraudster',\n",
       "       'spammer_limited', 'spammer_noinvite', 'locked', 'tos_lock',\n",
       "       'tos_warn', 'fraudster_att', 'spammer_web', 'spammer'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_type'].unique()\n",
    "df['acct_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "14332     True\n",
       "14333    False\n",
       "14334    False\n",
       "14335    False\n",
       "14336     True\n",
       "Name: fraud, Length: 14337, dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "df['fraud'] = df['acct_type'].apply(lambda x: 'fraud' in x)\n",
    "df['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['acct_type'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13044"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "df[df['fraud']==True]['fraud'].count()\n",
    "df[df['fraud']==False]['fraud'].count()\n",
    "# Fraud = ~10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "features = ['body_length'    ,\n",
    "'channels'       ,\n",
    "'delivery_method',\n",
    "'has_logo'       ,\n",
    "'name_length'    ,\n",
    "'org_facebook'   ,\n",
    "'org_twitter'    ,\n",
    "'sale_duration'  ,\n",
    "'sale_duration2' ,\n",
    "'user_age'       ,\n",
    "'fraud']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoping the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) Preprocessing\n",
    "- Convert dates to dt format\n",
    "- Convert binary categories to boolean\n",
    "\n",
    "2.) Models to Try\n",
    "\n",
    "3.) Metric to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "X = df.drop(columns=['fraud'])\n",
    "y = df['fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body_length        3533\n",
       "channels           3533\n",
       "delivery_method    3533\n",
       "has_logo           3533\n",
       "name_length        3533\n",
       "org_facebook       3533\n",
       "org_twitter        3533\n",
       "sale_duration      3533\n",
       "sale_duration2     3533\n",
       "user_age           3533\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.count()\n",
    "X_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def logistic_model(X, y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    #select the columns with numerical/categorical data\n",
    "    #X = X.loc[:, (X.dtypes == np.float64) or (X.dtypes == np.int64)]\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y)\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    #fit model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_valid, y_valid)\n",
    "    coeffs = pd.DataFrame(model.coef_, columns=X_train.columns)\n",
    "    print(coeffs)\n",
    "    tn, fp, fn, tp = confusion_matrix(model.predict(X_valid), y_valid).ravel()\n",
    "    \n",
    "    return model, accuracy, (tn, fp, fn, tp)\n",
    "\n",
    "\n",
    "def SGD_model(X, y):\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y)\n",
    "    \n",
    "    #fit model\n",
    "    model = SGDClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_valid, y_valid)\n",
    "    tn, fp, fn, tp = confusion_matrix(model.predict(X_valid), y_valid).ravel()\n",
    "  \n",
    "    \n",
    "    return model, accuracy, (tn, fp, fn, tp)\n",
    "    \n",
    "def rf_model(X,y):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y)\n",
    "    \n",
    "    #fit model\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_valid, y_valid)\n",
    "    tn, fp, fn, tp = confusion_matrix(model.predict(X_valid), y_valid).ravel()\n",
    "    \n",
    "    \n",
    "    return model, accuracy, (tn, fp, fn, tp)\n",
    "\n",
    "def gradient_model(X,y):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y)\n",
    "    \n",
    "    #fit model\n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_valid, y_valid)\n",
    "    tn, fp, fn, tp = confusion_matrix(model.predict(X_valid), y_valid).ravel()\n",
    "    \n",
    "    \n",
    "    return model, accuracy, (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   body_length  channels  delivery_method  has_logo  name_length  \\\n",
      "0    -0.000058 -0.041529        -0.043709 -0.009073    -0.003936   \n",
      "\n",
      "   org_facebook  org_twitter  sale_duration  sale_duration2  user_age  \n",
      "0     -0.065385    -0.134828       0.027722       -0.057248 -0.002832  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobmullins/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 0.92,\n",
       " (2438, 212, 0, 0))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "               early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "               l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "               max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "               power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "               validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " 0.9181132075471699,\n",
       " (2353, 132, 85, 80))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                            learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                            max_features=None, max_leaf_nodes=None,\n",
       "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                            min_samples_leaf=1, min_samples_split=2,\n",
       "                            min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                            n_iter_no_change=None, presort='deprecated',\n",
       "                            random_state=None, subsample=1.0, tol=0.0001,\n",
       "                            validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False),\n",
       " 0.9645283018867925,\n",
       " (2415, 71, 23, 141))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False),\n",
       " 0.9645283018867925,\n",
       " (2408, 64, 30, 148))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_length</th>\n",
       "      <th>channels</th>\n",
       "      <th>delivery_method</th>\n",
       "      <th>has_logo</th>\n",
       "      <th>name_length</th>\n",
       "      <th>org_facebook</th>\n",
       "      <th>org_twitter</th>\n",
       "      <th>sale_duration</th>\n",
       "      <th>sale_duration2</th>\n",
       "      <th>user_age</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3718</th>\n",
       "      <td>3125</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7461</th>\n",
       "      <td>6325</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61</td>\n",
       "      <td>1240</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8003</th>\n",
       "      <td>3501</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>1848</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76</td>\n",
       "      <td>455</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6764</th>\n",
       "      <td>3298</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1173</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6726</th>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>313</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>142</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>2402</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13490</th>\n",
       "      <td>795</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       body_length  channels  delivery_method  has_logo  name_length  \\\n",
       "3718          3125         8              0.0         1           67   \n",
       "7461          6325         8              1.0         1           72   \n",
       "8003          3501         0              1.0         1           28   \n",
       "6332          1848         0              0.0         1           36   \n",
       "6764          3298         0              1.0         1           57   \n",
       "...            ...       ...              ...       ...          ...   \n",
       "6726           334         0              0.0         0           38   \n",
       "1380           313        11              0.0         1           48   \n",
       "4041          2402        11              0.0         1           27   \n",
       "13490          795         0              0.0         1           13   \n",
       "3720          2004         5              0.0         1           23   \n",
       "\n",
       "       org_facebook  org_twitter  sale_duration  sale_duration2  user_age  \\\n",
       "3718            9.0         13.0           44.0              45         0   \n",
       "7461            0.0          0.0           61.0              61      1240   \n",
       "8003           15.0         16.0          134.0             360         0   \n",
       "6332           20.0         10.0           75.0              76       455   \n",
       "6764            0.0          0.0           19.0              19      1173   \n",
       "...             ...          ...            ...             ...       ...   \n",
       "6726            0.0          0.0            4.0               4         0   \n",
       "1380            0.0          0.0          142.0             142        36   \n",
       "4041            0.0          0.0           35.0              35         0   \n",
       "13490           0.0          0.0           40.0              40         0   \n",
       "3720           23.0          0.0           26.0              26         3   \n",
       "\n",
       "       fraud  \n",
       "3718   False  \n",
       "7461   False  \n",
       "8003   False  \n",
       "6332   False  \n",
       "6764   False  \n",
       "...      ...  \n",
       "6726    True  \n",
       "1380   False  \n",
       "4041   False  \n",
       "13490   True  \n",
       "3720   False  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "random_subset = df3.sample(n=100)\n",
    "random_subset.to_csv('test_script_examples.csv', index=False)\n",
    "random_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('test_script_examples.csv') as fd:\n",
    "#    reader=csv.reader(fd)\n",
    "#    #test_row=next(reader)\n",
    "#    next(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_script_examples.csv') as fd:\n",
    "    reader=csv.reader(fd)\n",
    "    interestingrow=[row for idx, row in enumerate(reader) if idx in [np.random.randint(1,100)]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2523', '0', '0.0', '1', '34', '20.0', '0.0', '13.0', '14', '1308', 'False']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interestingrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.523e+03, 0.000e+00, 0.000e+00, 1.000e+00, 3.400e+01, 2.000e+01,\n",
       "       0.000e+00, 1.300e+01, 1.400e+01, 1.308e+03])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[]\n",
    "for x in interestingrow:\n",
    "    try:l.append(float(x))\n",
    "    except:l.append(bool(x))\n",
    "\n",
    "interestingrow\n",
    "\n",
    "np.array(l[:-1])\n",
    "\n",
    "## for predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('test_script_examples.csv') as fd:\n",
    "    reader=csv.reader(fd)\n",
    "    interestingrow=[row for idx, row in enumerate(reader) if idx in (0,np.random.randint(1,100))][1]\n",
    "\n",
    "interestingrow\n",
    "\n",
    "l=[]\n",
    "for x in interestingrow:\n",
    "    try:l.append(float(x))\n",
    "    except:l.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6422.0, 5.0, 1.0, 1.0, 41.0, 15.0, 15.0, 104.0, 121.0, 169.0, 'False']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.422e+03, 5.000e+00, 1.000e+00, 1.000e+00, 4.100e+01, 1.500e+01,\n",
       "       1.500e+01, 1.040e+02, 1.210e+02, 1.690e+02])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=pd.Series(l[:-1])\n",
    "truth=pd.Series(l[-1])\n",
    "\n",
    "np.array(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['False'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, accuracy, (tn, fp, fn, tp) = rf_model(X_train, y_train)\n",
    "\n",
    "#pickle model\n",
    "from joblib import dump, load\n",
    "dump(model, 'modelpickle.joblib')\n",
    "\n",
    "#unpickle\n",
    "model = load('modelpickle.joblib')\n",
    "\n",
    "model.predict(np.array(input).reshape(1,-1))\n",
    "\n",
    "np.array(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sgdmodelpickle.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_model, accuracy, (tn, fp, fn, tp) = SGD_model(X_train, y_train)\n",
    "dump(sgd_model, 'sgdmodelpickle.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-fcff13a65d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_script_examples.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#interestingrow=[row for idx, row in enumerate(reader) if idx == np.random.randint(1,101)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "with open('test_script_examples.csv') as fd:\n",
    "    reader=csv.reader(fd)\n",
    "    interestingrows=[row for idx, row in enumerate(reader)]\n",
    "    if idx == np.random.randint(1,101):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_script_examples.csv') as fd:\n",
    "    reader=csv.reader(fd)\n",
    "    interestingrows=[row for idx, row in enumerate(reader)]\n",
    "    interestingrow = interestingrows[np.random.randint(1,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python flask/predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"app\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n",
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\n",
      " * Restarting with fsevents reloader\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 940-060-902\n",
      "127.0.0.1 - - [29/May/2020 11:59:22] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/May/2020 11:59:23] \"\u001b[33mGET /vendor/bootstrap/css/bootstrap.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [29/May/2020 11:59:23] \"\u001b[33mGET /vendor/jquery/jquery.slim.min.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [29/May/2020 11:59:23] \"\u001b[33mGET /vendor/bootstrap/js/bootstrap.bundle.min.js HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "!python flask/app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
